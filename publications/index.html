<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Luis Oala</title> <meta name="author" content="Luis Oala"> <meta name="description" content=""> <meta name="keywords" content="oala, luis oala, machine learning, aiaudit, 2ml, metrological machine learning, mml, data drift, data optimality, data synthesis, data-centric, data centric, dmlr"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://luisoala.net/publications/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Luis </span>Oala</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">Talks</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <h2 id="conferences-and-journals">Conferences and journals</h2> <div class="publications"> <h2 class="year">2024</h2> <h2 class="year">2023</h2> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="oala2023data" class="col-sm-8"> <div class="title">Data Models for Dataset Drift Controls in Machine Learning With Optical Images</div> <div class="author"> <em>Luis Oala</em>, Marco Aversa, Gabriel Nobis, Kurt Willis, Yoan Neuenschwander, Michèle Buck, Christian Matek, Jerome Extermann, Enrico Pomarico, Wojciech Samek, and  others</div> <div class="periodical"> <em>Transactions on Machine Learning Research (TMLR)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="aversa2023diffinfinite" class="col-sm-8"> <div class="title">DiffInfinite: Large Mask-Image Synthesis via Parallel Random Patch Diffusion in Histopathology</div> <div class="author"> Marco Aversa, Gabriel Nobis, Miriam Hägele, Kai Standvoss, Mihaela Chirica, Roderick Murray-Smith, Ahmed Alaa, Lukas Ruff, Daniela Ivanova, Wojciech Samek, and  others</div> <div class="periodical"> <em>arXiv preprint arXiv:2306.13384</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="akogo2023localized" class="col-sm-8"> <div class="title">Localized Data Work as a Precondition for Data-Centric ML: A Case Study of Full Lifecycle Crop Disease Identification in Ghana</div> <div class="author"> Darlington Akogo, Issah Samori, Cyril Akafia, Harriet Fiagbor, Andrews Kangah, Donald Kwame Asiedu, Kwabena Fuachie, and <em>Luis Oala</em> </div> <div class="periodical"> <em>arXiv preprint arXiv:2307.01767</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="year">2022</h2> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="ramirez2022dataset" class="col-sm-8"> <div class="title">Dataset Similarity to Assess Semi-supervised Learning Under Distribution Mismatch Between the Labelled and Unlabelled Datasets</div> <div class="author"> Saul Calderon Ramirez, <em>Luis Oala</em>, Jordina Torrentes-Barrena, Shengxiang Yang, David Elizondo, Armaghan Moemeni, Simon Colreavy-Donnelly, Wojciech Samek, Miguel Molina-Cabello, and Ezequiel Lopez-Rubio</div> <div class="periodical"> <em>IEEE Transactions on Artificial Intelligence</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="adler2022deutsche" class="col-sm-8"> <div class="title">Deutsche Normungsroadmap Künstliche Intelligenz</div> <div class="author"> Rasmus Adler, Andreas Bunte, Simon Burton, Jürgen Großmann, Alexander Jaschke, Philip Kleen, Jeanette Miriam Lorenz, Jackie Ma, Karla Markert, Henri Meeß, and  others</div> <div class="periodical"> <em></em> 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="parziale2022machine" class="col-sm-8"> <div class="title">Machine Learning for Health (ML4H) 2022</div> <div class="author"> Antonio Parziale, Monica Agrawal, Shengpu Tang, Kristen Severson, <em>Luis Oala</em>, Adarsh Subbaswamy, Sayantan Kumar, Elora Schoerverth, Stefan Hegselmann, Helen Zhou, and  others</div> <div class="periodical"> <em>In Machine Learning for Health</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="parziale2022machinf" class="col-sm-8"> <div class="title">Machine Learning for Health symposium 2022–Extended Abstract track</div> <div class="author"> Antonio Parziale, Monica Agrawal, Shalmali Joshi, Irene Y Chen, Shengpu Tang, <em>Luis Oala</em>, and Adarsh Subbaswamy</div> <div class="periodical"> <em>arXiv preprint arXiv:2211.15564</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="fehr2022piloting" class="col-sm-8"> <div class="title">Piloting A Survey-Based Assessment of Transparency and Trustworthiness with Three Medical AI Tools</div> <div class="author"> Jana Fehr, Giovanna Jaramillo-Gutierrez, <em>Luis Oala</em>, Matthias I Gröschel, Manuel Bierwirth, Pradeep Balachandran, Alixandro Werneck-Leite, and Christoph Lippert</div> <div class="periodical"> <em>In Healthcare</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="parziale2022proceedings" class="col-sm-8"> <div class="title">Proceedings of the 2nd Machine Learning for Health symposium</div> <div class="author"> Antonio Parziale, Agrawal Monica, Joshi Shalmali, Irene Y Chen, Tang Shengpu, Oala Luis, Subbaswamy Adarsh, and  others</div> <div class="periodical"> <em>PROCEEDINGS OF MACHINE LEARNING RESEARCH</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div> <div class="col-sm-2 preview"></div> <div id="robiclr2" class="col-sm-8"> <div class="title">Post-Hoc Domain Adaptation via Guided Data Homogenization</div> <div class="author"> Kurt Willis, and <em>Luis Oala</em> </div> <div class="periodical"> <em>In ICLR 2021 Workshop on Robust and Reliable Machine Learning in the Real World Workshop (RobustML)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://sites.google.com/connect.hku.hk/robustml-2021/home?authuser%20=%200" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Addressing shifts in data distributions is an important prerequisite for the deployment of deep learning models to real-world settings. A general approach to this problem involves the adjustment of models to a new domain through transfer learning. However, in many cases, this is not applicable in a post-hoc manner to deployed models and further parameter adjustments jeopardize safety certifications that were established beforehand. In such a context, we propose to deal with changes in the data distribution via guided data homogenization which shifts the burden of adaptation from the model to the data. This approach makes use of information about the training data contained implicitly in the deep learning model to learn a domain transfer function. This allows for a targeted deployment of models to unknown scenarios without changing the model itself. We demonstrate the potential of data homogenization through experiments on the CIFAR-10 and MNIST data sets.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div> <div class="col-sm-2 preview"></div> <div id="robiclr1" class="col-sm-8"> <div class="title">More Than Meets The Eye: Semi-supervised Learning Under Non-IID Data</div> <div class="author"> Saul Calderon-Ramirez, and <em>Luis Oala</em> </div> <div class="periodical"> <em>In ICLR 2021 Workshop on Robust and Reliable Machine Learning in the Real World Workshop (RobustML)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://sites.google.com/connect.hku.hk/robustml-2021/home?authuser%20=%200" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>In absence of explicit knowledge about data models it is often assumed that a semantic match between labelled and unlabelled data is desirable in the context of semi-supervised deep learning (SSDL). In this work, we demonstrate the limits of semantic data set matching. We present and make available a comprehensive simulation sandbox, called non-IID-SSDL, for stress testing SSDL algorithms under various non-IID configurations. We show that semantic data set matching can degrade the performance for state of the art SSDL. In addition, we demonstrate that simple dissimilarity measures in the feature space of a generic classifier offer a promising and more reliable matching criterion.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">BVM</abbr></div> <div class="col-sm-2 preview"></div> <div id="10.1007/978-3-658-33198-6_79" class="col-sm-8"> <div class="title">Interval Neural Networks as Instability Detectors for Image Reconstructions</div> <div class="author"> Jan Macdonald, Maximilian März, <em>Luis Oala</em>, and Wojciech Samek</div> <div class="periodical"> <em>In Bildverarbeitung für die Medizin 2021</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/chapter/10.1007%2F978-3-658-33198-6_79" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.springer.com/chapter/10.1007%2F978-3-658-33198-6_79" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This work investigates the detection of instabilities that may occur when utilizing deep learning models for image reconstruction tasks. Although neural networks often empirically outperform traditional reconstruction methods, their usage for sensitive medical applications remains controversial. Indeed, in a recent series of works, it has been demonstrated that deep learning approaches are susceptible to various types of instabilities, caused for instance by adversarial noise or out-ofdistribution features. It is argued that this phenomenon can be observed regardless of the underlying architecture and that there is no easy remedy. Based on this insight, the present work demonstrates, how uncertainty quantification methods can be employed as instability detectors. In particular, it is shown that the recently proposed Interval Neural Networks are highly effective in revealing instabilities of reconstructions. Such an ability is crucial to ensure a safe use of deep learning-based methods for medical image reconstruction.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IJCARS</abbr></div> <div class="col-sm-2 preview"></div> <div id="oala2021detecting" class="col-sm-8"> <div class="title">Detecting failure modes in image reconstructions with interval neural network uncertainty</div> <div class="author"> <em>Luis Oala</em>, Cosmas Heiß, Jan Macdonald, Maximilian März, Gitta Kutyniok, and Wojciech Samek</div> <div class="periodical"> <em>International Journal of Computer Assisted Radiology and Surgery</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://link.springer.com/article/10.1007/s11548-021-02482-2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://link.springer.com/content/pdf/10.1007/s11548-021-02482-2.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/luisoala/inn" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Purpose The quantitative detection of failure modes is important for making deep neural networks reliable and usable at scale. We consider three examples for common failure modes in image reconstruction and demonstrate the potential of uncertainty quantification as a fine-grained alarm system. Methods We propose a deterministic, modular and lightweight approach called Interval Neural Network (INN) that produces fast and easy to interpret uncertainty scores for deep neural networks. Importantly, INNs can be constructed post hoc for already trained prediction networks. We compare it against state-of-the-art baseline methods (MCDROP, PROBOUT). Results We demonstrate on controlled, synthetic inverse problems the capacity of INNs to capture uncertainty due to noise as well as directional error information. On a real-world inverse problem with human CT scans, we can show that INNs produce uncertainty scores which improve the detection of all considered failure modes compared to the baseline methods. Conclusion Interval Neural Networks offer a promising tool to expose weaknesses of deep image reconstruction models and ultimately make them more reliable. The fact that they can be applied post hoc to equip already trained deep neural network models with uncertainty scores makes them particularly interesting for deployment.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="calderon2021improving" class="col-sm-8"> <div class="title">Improving uncertainty estimation with semi-supervised deep learning for COVID-19 detection using chest X-ray images</div> <div class="author"> Saul Calderon-Ramirez, Shengxiang Yang, Armaghan Moemeni, Simon Colreavy-Donnelly, David A Elizondo, <em>Luis Oala</em>, Jorge Rodrı́guez-Capitán, Manuel Jiménez-Navarro, Ezequiel López-Rubio, and Miguel A Molina-Cabello</div> <div class="periodical"> <em>Ieee Access</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="willis2021post" class="col-sm-8"> <div class="title">Post-hoc domain adaptation via guided data homogenization</div> <div class="author"> Kurt Willis, and <em>Luis Oala</em> </div> <div class="periodical"> <em>arXiv preprint arXiv:2104.03624</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="oala2021detectinh" class="col-sm-8"> <div class="title">Detecting failure modes in image reconstructions with interval neural network uncertainty</div> <div class="author"> <em>Luis Oala</em>, Cosmas Heiß, Jan Macdonald, Maximilian März, Gitta Kutyniok, and Wojciech Samek</div> <div class="periodical"> <em>International Journal of Computer Assisted Radiology and Surgery</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="oala2021machine" class="col-sm-8"> <div class="title">Machine learning for health: algorithm auditing &amp; quality control</div> <div class="author"> <em>Luis Oala</em>, Andrew G Murchison, Pradeep Balachandran, Shruti Choudhary, Jana Fehr, Alixandro Werneck Leite, Peter G Goldschmidt, Christian Johner, Elora DM Schörverth, Rose Nakasi, and  others</div> <div class="periodical"> <em>Journal of medical systems</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="roy2021machine" class="col-sm-8"> <div class="title">Machine learning for health (ml4h) 2021</div> <div class="author"> Subhrajit Roy, Stephen Pfohl, Girmaw Abebe Tadesse, <em>Luis Oala</em>, Fabian Falck, Yuyin Zhou, Liyue Shen, Ghada Zamzmi, Purity Mugambi, Ayah Zirikly, and  others</div> <div class="periodical"> <em>In Machine Learning for Health</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="falck2021collection" class="col-sm-8"> <div class="title">A collection of the accepted abstracts for the Machine Learning for Health (ML4H) symposium 2021</div> <div class="author"> Fabian Falck, Yuyin Zhou, Emma Rocheteau, Liyue Shen, <em>Luis Oala</em>, Girmaw Abebe, Subhrajit Roy, Stephen Pfohl, Emily Alsentzer, and Matthew McDermott</div> <div class="periodical"> <em>arXiv e-prints</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="year">2020</h2> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/ml4haudit-preview-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/ml4haudit-preview-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/ml4haudit-preview-1400.webp"></source> <img src="/assets/img/publication_preview/ml4haudit-preview.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="ml4haudit-preview.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pmlr-v136-oala20a" class="col-sm-8"> <div class="title">ML4H Auditing: From Paper to Practice</div> <div class="author"> <em>Luis Oala</em>, Jana Fehr, Luca Gilli, Pradeep Balachandran, Alixandro Werneck Leite, Saul Calderon-Ramirez, Danny Xie Li, Gabriel Nobis, Erick Alejandro Munoz Alvarado, Giovanna Jaramillo-Gutierrez, Christian Matek, Arun Shroff, Ferath Kherif, Bruno Sanguinetti, and Thomas Wiegand</div> <div class="periodical"> <em>In Proceedings of the Machine Learning for Health NeurIPS Workshop</em>, 11 dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://proceedings.mlr.press/v136/oala20a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="http://proceedings.mlr.press/v136/oala20a/oala20a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/slides/ML4H_NeurIPS2020_Slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Healthcare systems are currently adapting to digital technologies, producing large quantities of novel data. Based on these data, machine-learning algorithms have been developed to support practitioners in labor-intensive workflows such as diagnosis, prognosis, triage or treatment of disease. However, their translation into medical practice is often hampered by a lack of careful evaluation in different settings. Efforts have started worldwide to establish guidelines for evaluating machine learning for health (ML4H) tools, highlighting the necessity to evaluate models for bias, interpretability, robustness, and possible failure modes. However, testing and adopting these guidelines in practice remains an open challenge. In this work, we target the paper-to-practice gap by applying an ML4H audit framework proposed by the ITU/WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) to three use cases: diagnostic prediction of diabetic retinopathy, diagnostic prediction of Alzheimer’s disease, and cytomorphologic classification for leukemia diagnostics. The assessment comprises dimensions such as bias, interpretability, and robustness. Our results highlight the importance of fine-grained and caseadapted quality assessment, provide support for incorporating proposed quality assessment considerations of ML4H during the entire development life cycle, and suggest improvements for future ML4H reference evaluation frameworks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pmlr-v136-oala20a</span><span class="p">,</span>
  <span class="na">award</span> <span class="p">=</span> <span class="s">{Spotlight&lt;br&gt;Top 10%}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ML4H Auditing: From Paper to Practice}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Oala, Luis and Fehr, Jana and Gilli, Luca and Balachandran, Pradeep and Leite, Alixandro Werneck and Calderon-Ramirez, Saul and Li, Danny Xie and Nobis, Gabriel and Alvarado, Erick Alejandro Munoz and Jaramillo-Gutierrez, Giovanna and Matek, Christian and Shroff, Arun and Kherif, Ferath and Sanguinetti, Bruno and Wiegand, Thomas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Machine Learning for Health NeurIPS Workshop}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{280--317}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Alsentzer, Emily and McDermott, Matthew B. A. and Falck, Fabian and Sarkar, Suproteem K. and Roy, Subhrajit and Hyland, Stephanie L.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{136}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{11 Dec}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://proceedings.mlr.press/v136/oala20a.html}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div> <div class="col-sm-2 preview"></div> <div id="OalUDL20" class="col-sm-8"> <div class="title">Detecting Failure Modes in Image Reconstructions with Interval Neural Network Uncertainty</div> <div class="author"> <em>Luis Oala</em>, Cosmas Heiß, Jan Macdonald, Maximilian März, Wojciech Samek, and Gitta Kutyniok</div> <div class="periodical"> <em>In ICML 2020 Workshop on Uncertainty &amp; Robustness in Deep Learning</em>, 11 dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://sites.google.com/view/udlworkshop2020/home" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="http://www.gatsby.ucl.ac.uk/%C2%A0balaji/udl2020/accepted-papers/UDL2020-paper-011.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/slides/UDL2020_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>The quantitative detection of failure modes is important for making deep neural networks reliable and usable at scale. We consider three examples for failure modes in image reconstruction problems and demonstrate the potential of uncertainty quantification as a fine-grained alarm system. We propose a deterministic, modular and lightweight approach, called Interval Neural Networks, that produces fast and easy to interpret uncertainty scores which improve the detection of failure modes across four out of five image reconstruction experiments.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div class="col-sm-2 preview"></div> <div id="oala2020ml4h" class="col-sm-8"> <div class="title">Ml4h auditing: From paper to practice</div> <div class="author"> <em>Luis Oala</em>, Jana Fehr, Luca Gilli, Pradeep Balachandran, Alixandro Werneck Leite, Saul Calderon-Ramirez, Danny Xie Li, Gabriel Nobis, Erick Alejandro Muñoz Alvarado, Giovanna Jaramillo-Gutierrez, and  others</div> <div class="periodical"> <em>In Machine learning for health</em>, 11 dec 2020 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> </div> <h2 id="preprints">Preprints</h2> <div class="publications"> <h2 class="year">2024</h2> <h2 class="year">2023</h2> <h2 class="year">2022</h2> <h2 class="year">2021</h2> <h2 class="year">2020</h2> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div> <div class="col-sm-2 preview"></div> <div id="oala2020interval" class="col-sm-8"> <div class="title">Interval Neural Networks: Uncertainty Scores</div> <div class="author"> <em>Luis Oala</em>, Cosmas Heiß, Jan Macdonald, Maximilian März, Wojciech Samek, and Gitta Kutyniok</div> <div class="periodical"> 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2003.11566" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2003.11566.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We propose a fast, non-Bayesian method for producing uncertainty scores in the output of pre-trained deep neural networks (DNNs) using a data-driven interval propagating network. This interval neural network (INN) has interval valued parameters and propagates its input using interval arithmetic. The INN produces sensible lower and upper bounds encompassing the ground truth. We provide theoretical justification for the validity of these bounds. Furthermore, its asymmetric uncertainty scores offer additional, directional information beyond what Gaussian-based, symmetric variance estimation can provide. We find that noise in the data is adequately captured by the intervals produced with our method. In numerical experiments on an image reconstruction task, we demonstrate the practical utility of INNs as a proxy for the prediction error in comparison to two state-of-the-art uncertainty quantification methods. In summary, INNs produce fast, theoretically justified uncertainty scores for DNNs that are easy to interpret, come with added information and pose as improved error proxies - features that may prove useful in advancing the usability of DNNs especially in sensitive applications such as health care.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div> <div class="col-sm-2 preview"></div> <div id="calderonramirez2020mixmood" class="col-sm-8"> <div class="title">MixMOOD: A systematic approach to class distribution mismatch in semi-supervised learning using deep dataset dissimilarity measures</div> <div class="author"> Saul Calderon-Ramirez, <em>Luis Oala</em>, Jordina Torrents-Barrena, Shengxiang Yang, Armaghan Moemeni, Wojciech Samek, and Miguel A. Molina-Cabello</div> <div class="periodical"> 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2006.07767" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2006.07767.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>In this work, we propose MixMOOD - a systematic approach to mitigate effect of class distribution mismatch in semi-supervised deep learning (SSDL) with MixMatch. This work is divided into two components: (i) an extensive out of distribution (OOD) ablation test bed for SSDL and (ii) a quantitative unlabelled dataset selection heuristic referred to as MixMOOD. In the first part, we analyze the sensitivity of MixMatch accuracy under 90 different distribution mismatch scenarios across three multi-class classification tasks. These are designed to systematically understand how OOD unlabelled data affects MixMatch performance. In the second part, we propose an efficient and effective method, called deep dataset dissimilarity measures (DeDiMs), to compare labelled and unlabelled datasets. The proposed DeDiMs are quick to evaluate and model agnostic. They use the feature space of a generic Wide-ResNet and can be applied prior to learning. Our test results reveal that supposed semantic similarity between labelled and unlabelled data is not a good heuristic for unlabelled data selection. In contrast, strong correlation between MixMatch accuracy and the proposed DeDiMs allow us to quantitatively rank different unlabelled datasets ante hoc according to expected MixMatch accuracy. This is what we call MixMOOD. Furthermore, we argue that the MixMOOD approach can aid to standardize the evaluation of different semi-supervised learning techniques under real world scenarios involving out of distribution data.</p> </div> </div> </div> </li> </ol> </div> <h2 id="standardization">Standardization</h2> <div class="publications"> <h2 class="year">2024</h2> <h2 class="year">2023</h2> <h2 class="year">2022</h2> <h2 class="year">2021</h2> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ITU/WHO</abbr></div> <div class="col-sm-2 preview"></div> <div id="regGMLP" class="col-sm-8"> <div class="title">Good practices for health applications of machine learning: Considerations for manufacturers and regulators</div> <div class="author"> Christian Johner, Pradeep Balachandran, <em>Luis Oala</em>, Aaron .Y. Lee, Alixandro Werneck Leite, Andrew Murchison, Anle Lin, Christoph Molnar, Juliet Rumball-Smith, Pat Baird, Peter. G. Goldschmidt, Pierre Quartarolo, Shan Xu, Sven Piechottka, and Zack Hornberger</div> <div class="periodical"> <em>In Proceedings of the ITU/WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) - Meeting K</em>, Itu/who 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://extranet.itu.int/sites/itu-t/focusgroups/ai4h/_layouts/15/WopiFrame.aspx?sourcedoc=%7B828882B2-4941-452C-8A61-F4DDE5802C2A%7D&amp;file=FGAI4H-K-039.docx&amp;action=default&amp;CT=1614782367878&amp;OR=DocLibClassicUI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/standards/FGAI4H-K-039.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This document contains the latest draft of the FG-AI4H deliverable DEL02.2 "Good practices for health applications of machine learning: Considerations for manufacturers and regulators". This deliverable defines a set of guidelines intended to serve the AI solution developers/manufacturers on how to do conduct a comprehensive requirements analysis and to streamline the conformity assessment procedures to ensure regulatory compliance for the AI based Medical Devices (AI/ML-MD).</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ITU/WHO</abbr></div> <div class="col-sm-2 preview"></div> <div id="EPandRP" class="col-sm-8"> <div class="title">FG-AI4H Open Code Initiative - Evaluation and Reporting Package</div> <div class="author"> Elora Schörverth, Steffen Vogler, Pradeep Balachandran, Alixandro Werneck Leite, Danny Xie Li, Kamran Ali,  Garcia, Dominik Schneider, Joachim Krois, Marc Lecoultre, Shobha Iyer, Shruti Choudhary, and <em>Luis Oala</em> </div> <div class="periodical"> <em>In Proceedings of the ITU/WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) - Meeting K</em>, Jan 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://extranet.itu.int/sites/itu-t/focusgroups/ai4h/_layouts/15/WopiFrame.aspx?sourcedoc=%7BD810F149-A5D1-4380-B128-5AC4F8AC07EC%7D&amp;file=FGAI4H-K-043-A01.pptx&amp;action=default&amp;CT=1614792781425&amp;OR=DocLibClassicUI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/standards/FGAI4H-K-043-A01.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/aiaudit-org/fgai4h-evaluation-platform" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Presentation of the software components developed by WG-DAISAM for automating the FG-AI4H evaluation process.</p> </div> </div> </div> </li> </ol> <h2 class="year">2020</h2> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ITU/WHO</abbr></div> <div class="col-sm-2 preview"></div> <div id="daisamref" class="col-sm-8"> <div class="title">Data and artificial intelligence assessment methods (DAISAM) reference</div> <div class="author"> <em>Luis Oala</em>, Pradeep Balachandran, Federico Cabitza, Saul Calderon Ramirez, Alexandre Chiavegatto Filho, Fabian Eitel, Jérôme Extermann, Jana Fehr, Stephane Ghozzi, Luca Gilli, Giovanna Jaramillo-Gutierrez, Quist-Aphetsi Kester, Shalini Kurapati, Stefan Konigorski, Joachim Krois, and <span class="more-authors" title="click to view 10 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '10 more authors' ? 'Christoph Lippert, Jörg Martin, Alberto Merola, Andrew Murchison, Sebastian Niehaus, Kerstin Ritter, Wojciech Samek, Bruno Sanguinetti, Anne Schwerk, Vignesh Srinivasan' : '10 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '0'); ">10 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the ITU/WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) - Meeting I</em>, May 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://extranet.itu.int/sites/itu-t/focusgroups/ai4h/_layouts/15/WopiFrame.aspx?sourcedoc=%7B32FEDFE7-FAF9-476E-81EC-AD06FB956528%7D&amp;file=FGAI4H-I-035.docx&amp;action=default&amp;CT=1614746953719&amp;OR=DocLibClassicUI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/standards/FGAI4H-I-035.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This document, Data and artificial intelligence assessment methods (DAISAM) reference, is the reference collection of WG-DAISAM for assessment methods of data and artificial intelligence quality evaluation. This document also constitutes subsection 7.3 of the FG-AI4H deliverable 7.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ITU/WHO</abbr></div> <div class="col-sm-2 preview"></div> <div id="AuditReportTemplate" class="col-sm-8"> <div class="title">Data and artificial intelligence assessment methods (DAISAM) Audit Reporting Template</div> <div class="author"> Boris Verks, and <em>Luis Oala</em> </div> <div class="periodical"> <em>In Proceedings of the ITU/WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) - Meeting J</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://extranet.itu.int/sites/itu-t/focusgroups/ai4h/_layouts/15/WopiFrame.aspx?sourcedoc=%7B3DAE32A1-24FF-4F4D-A735-F378056BA6CF%7D&amp;file=FGAI4H-J-048.docx&amp;action=default&amp;CT=1614791061573&amp;OR=DocLibClassicUI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/standards/FGAI4H-J-048.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Standardized templates to report results for the assessment processes developed by WG-DAISAM. In this version the, template comprises three elements: Data Specification Sheet, ML Model Specification Sheet and ML Model Summary Findings.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Luis Oala. Thanks to <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">Maruan</a> for the neat theme base </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>