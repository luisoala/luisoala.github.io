---
---

%special fields include abbr, award, pdf, html, abstract, slides, video, selected

@InProceedings{pmlr-v136-oala20a,
  abbr = {NeurIPS},
  award = {Spotlight<br>Top 10%},
  title = 	 {ML4H Auditing: From Paper to Practice},
  author =       {Oala, Luis and Fehr, Jana and Gilli, Luca and Balachandran, Pradeep and Leite, Alixandro Werneck and Calderon-Ramirez, Saul and Li, Danny Xie and Nobis, Gabriel and Alvarado, Erick Alejandro Munoz and Jaramillo-Gutierrez, Giovanna and Matek, Christian and Shroff, Arun and Kherif, Ferath and Sanguinetti, Bruno and Wiegand, Thomas},
  booktitle = 	 {Proceedings of the Machine Learning for Health NeurIPS Workshop},
  pages = 	 {280--317},
  year = 	 {2020},
  editor = 	 {Emily Alsentzer and Matthew B. A. McDermott and Fabian Falck and Suproteem K. Sarkar and Subhrajit Roy and Stephanie L. Hyland},
  volume = 	 {136},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {11 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v136/oala20a/oala20a.pdf},
  url = 	 {http://proceedings.mlr.press/v136/oala20a.html},
  html = {http://proceedings.mlr.press/v136/oala20a.html},
  abstract = 	 {Healthcare systems are currently adapting to digital technologies, producing large quantities of novel data. Based on these data, machine-learning algorithms have been developed to support practitioners in labor-intensive workflows such as diagnosis, prognosis, triage or treatment of disease. However, their translation into medical practice is often hampered by a lack of careful evaluation in different settings. Efforts have started worldwide to establish guidelines for evaluating machine learning for health (ML4H) tools, highlighting the necessity to evaluate models for bias, interpretability, robustness, and possible failure modes. However, testing and adopting these guidelines in practice remains an open challenge. In this work, we target the paper-to-practice gap by applying an ML4H audit framework proposed by the ITU/WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) to three use cases: diagnostic prediction of diabetic retinopathy, diagnostic prediction of Alzheimer’s disease, and cytomorphologic classification for leukemia diagnostics. The assessment comprises dimensions such as bias, interpretability, and robustness. Our results highlight the importance of fine-grained and caseadapted quality assessment, provide support for incorporating proposed quality assessment considerations of ML4H during the entire development life cycle, and suggest improvements for future ML4H reference evaluation frameworks.},
  slides = {slides/ML4H_NeurIPS2020_Slides.pdf},
  video = {https://slideslive.at/38941015/ml4h-auditing-from-paper-to-practice},
  selected = {true}
}

@InProceedings{OalUDL20,
  abbr = {ICML},
  award = {Spotlight<br>Top 10%},
  author = {Luis Oala and Cosmas Hei{\ss} and Jan Macdonald and Maximilian M{\"a}rz and Wojciech Samek and Gitta Kutyniok},
  title = {Detecting Failure Modes in Image Reconstructions with Interval Neural Network Uncertainty},
  booktitle = {ICML 2020 Workshop on Uncertainty & Robustness in Deep Learning},
  year = {2020},
  pages = {},
  url = {https://arxiv.org/abs/2003.11566},
  html = {https://sites.google.com/view/udlworkshop2020/home},
  pdf = {http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-011.pdf},
  abstract = {The quantitative detection of failure modes is important for making deep neural networks reliable and usable at scale. We consider three examples for failure modes in image reconstruction problems and demonstrate the potential of uncertainty quantification as a fine-grained alarm system. We propose a deterministic, modular and lightweight approach, called Interval Neural Networks, that produces fast and easy to interpret uncertainty scores which improve the detection of failure modes across four out of five image reconstruction experiments.},
  slides = {slides/UDL2020_slides.pdf},
  video = {https://slideslive.com/38930948},
  selected = {true}
}

@InProceedings{robiclr2,
  abbr = {ICLR},
  author = {Kurt Willis and Luis Oala},
  title = {Post-Hoc Domain Adaptation via Guided Data Homogenization},
  booktitle = {ICLR 2021 Workshop on Robust and Reliable Machine Learning in the Real World Workshop (RobustML)},
  year = {2021},
  pages = {},
  html = {https://sites.google.com/connect.hku.hk/robustml-2021/home?authuser=0},
  abstract = {Addressing shifts in data distributions is an important prerequisite for the deployment of deep learning models to real-world settings. A general approach to this problem involves the adjustment of models to a new domain through transfer learning. However, in many cases, this is not applicable in a post-hoc manner to deployed models and further parameter adjustments jeopardize safety certifications that were established beforehand. In such a context, we propose to deal with changes in the data distribution via guided data homogenization which shifts the burden of adaptation from the model to the data. This approach makes use of information about the training data contained implicitly in the deep learning model to learn a domain transfer function. This allows for a targeted deployment of models to unknown scenarios without changing the model itself. We demonstrate the potential of data homogenization through experiments on the CIFAR-10 and MNIST data sets.},
  selected = {true}
}


@InProceedings{robiclr1,
  abbr = {ICLR},
  author = {Saul Calderon-Ramirez and Luis Oala},
  title = {More Than Meets The Eye: Semi-supervised Learning Under Non-IID Data},
  booktitle = {ICLR 2021 Workshop on Robust and Reliable Machine Learning in the Real World Workshop (RobustML)},
  year = {2021},
  pages = {},
  html = {https://sites.google.com/connect.hku.hk/robustml-2021/home?authuser=0},
  abstract = {In absence of explicit knowledge about data models it is often assumed that a semantic match between labelled and unlabelled data is desirable in the context of semi-supervised deep learning (SSDL). In this work, we demonstrate the limits of semantic data set matching. We present and make available a comprehensive simulation sandbox, called non-IID-SSDL, for stress testing SSDL algorithms under various non-IID configurations. We show that semantic data set matching can degrade the performance for state of the art SSDL. In addition, we demonstrate that simple dissimilarity measures in the feature space of a generic classifier offer a promising and more reliable matching criterion.},
  selected = {true}
}

@InProceedings{10.1007/978-3-658-33198-6_79,
author="Macdonald, Jan
and M{\"a}rz, Maximilian
and Oala, Luis
and Samek, Wojciech",
editor="Palm, Christoph
and Deserno, Thomas M.
and Handels, Heinz
and Maier, Andreas
and Maier-Hein, Klaus
and Tolxdorff, Thomas",
title="Interval Neural Networks as Instability Detectors for Image Reconstructions",
booktitle="Bildverarbeitung f{\"u}r die Medizin 2021",
year="2021",
publisher="Springer Fachmedien Wiesbaden",
address="Wiesbaden",
pages="324--329",
abbr = {BVM},
award = {Best Paper Prize},
abstract="This work investigates the detection of instabilities that may occur when utilizing deep learning models for image reconstruction tasks. Although neural networks often empirically outperform traditional reconstruction methods, their usage for sensitive medical applications remains controversial. Indeed, in a recent series of works, it has been demonstrated that deep learning approaches are susceptible to various types of instabilities, caused for instance by adversarial noise or out-ofdistribution features. It is argued that this phenomenon can be observed regardless of the underlying architecture and that there is no easy remedy. Based on this insight, the present work demonstrates, how uncertainty quantification methods can be employed as instability detectors. In particular, it is shown that the recently proposed Interval Neural Networks are highly effective in revealing instabilities of reconstructions. Such an ability is crucial to ensure a safe use of deep learning-based methods for medical image reconstruction.",
isbn="978-3-658-33198-6",
url = {https://link.springer.com/chapter/10.1007%2F978-3-658-33198-6_79},
  html = {https://link.springer.com/chapter/10.1007%2F978-3-658-33198-6_79},
  pdf = {https://link.springer.com/chapter/10.1007%2F978-3-658-33198-6_79},
  selected = {true},
  awarddoc = {misc/BVM2021_Preis_1sterPlatz.pdf}
}

@article{oala2021detecting,
  title={Detecting failure modes in image reconstructions with interval neural network uncertainty},
  author={Oala, Luis and Hei{\ss}, Cosmas and Macdonald, Jan and M{\"a}rz, Maximilian and Kutyniok, Gitta and Samek, Wojciech},
  journal={International Journal of Computer Assisted Radiology and Surgery},
  pages={1--9},
  year={2021},
  publisher={Springer},
  selected={true},
  abstract={Purpose The quantitative detection of failure modes is important for making deep neural networks reliable and usable at scale. We consider three examples for common failure modes in image reconstruction and demonstrate the potential of uncertainty quantification as a fine-grained alarm system.  Methods We propose a deterministic, modular and lightweight approach called Interval Neural Network (INN) that produces fast and easy to interpret uncertainty scores for deep neural networks. Importantly, INNs can be constructed post hoc for already trained prediction networks. We compare it against state-of-the-art baseline methods (MCDROP, PROBOUT).  Results We demonstrate on controlled, synthetic inverse problems the capacity of INNs to capture uncertainty due to noise as well as directional error information. On a real-world inverse problem with human CT scans, we can show that INNs produce uncertainty scores which improve the detection of all considered failure modes compared to the baseline methods.  Conclusion Interval Neural Networks offer a promising tool to expose weaknesses of deep image reconstruction models and ultimately make them more reliable. The fact that they can be applied post hoc to equip already trained deep neural network models with uncertainty scores makes them particularly interesting for deployment.},
  abbr={IJCARS},
  html={https://link.springer.com/article/10.1007/s11548-021-02482-2},
  pdf={https://link.springer.com/content/pdf/10.1007/s11548-021-02482-2.pdf},
  code={https://github.com/luisoala/inn}
  
}

@inproceedings{oala2020ml4h,
  title={Ml4h auditing: From paper to practice},
  author={Oala, Luis and Fehr, Jana and Gilli, Luca and Balachandran, Pradeep and Leite, Alixandro Werneck and Calderon-Ramirez, Saul and Li, Danny Xie and Nobis, Gabriel and Alvarado, Erick Alejandro Mu{\~n}oz and Jaramillo-Gutierrez, Giovanna and others},
  booktitle={Machine learning for health},
  pages={280--317},
  year={2020},
  organization={PMLR}
}

@article{calderon2021improving,
  title={Improving uncertainty estimation with semi-supervised deep learning for COVID-19 detection using chest X-ray images},
  author={Calderon-Ramirez, Saul and Yang, Shengxiang and Moemeni, Armaghan and Colreavy-Donnelly, Simon and Elizondo, David A and Oala, Luis and Rodr{\'\i}guez-Capit{\'a}n, Jorge and Jim{\'e}nez-Navarro, Manuel and L{\'o}pez-Rubio, Ezequiel and Molina-Cabello, Miguel A},
  journal={Ieee Access},
  volume={9},
  pages={85442--85454},
  year={2021},
  publisher={IEEE}
}

@article{willis2021post,
  title={Post-hoc domain adaptation via guided data homogenization},
  author={Willis, Kurt and Oala, Luis},
  journal={arXiv preprint arXiv:2104.03624},
  year={2021}
}

@article{oala2021detecting,
  title={Detecting failure modes in image reconstructions with interval neural network uncertainty},
  author={Oala, Luis and Hei{\ss}, Cosmas and Macdonald, Jan and M{\"a}rz, Maximilian and Kutyniok, Gitta and Samek, Wojciech},
  journal={International Journal of Computer Assisted Radiology and Surgery},
  volume={16},
  pages={2089--2097},
  year={2021},
  publisher={Springer International Publishing}
}

@article{oala2021machine,
  title={Machine learning for health: algorithm auditing \& quality control},
  author={Oala, Luis and Murchison, Andrew G and Balachandran, Pradeep and Choudhary, Shruti and Fehr, Jana and Leite, Alixandro Werneck and Goldschmidt, Peter G and Johner, Christian and Sch{\"o}rverth, Elora DM and Nakasi, Rose and others},
  journal={Journal of medical systems},
  volume={45},
  pages={1--8},
  year={2021},
  publisher={Springer US}
}

@inproceedings{roy2021machine,
  title={Machine learning for health (ml4h) 2021},
  author={Roy, Subhrajit and Pfohl, Stephen and Tadesse, Girmaw Abebe and Oala, Luis and Falck, Fabian and Zhou, Yuyin and Shen, Liyue and Zamzmi, Ghada and Mugambi, Purity and Zirikly, Ayah and others},
  booktitle={Machine Learning for Health},
  pages={1--12},
  year={2021},
  organization={PMLR}
}

@article{falck2021collection,
  title={A collection of the accepted abstracts for the Machine Learning for Health (ML4H) symposium 2021},
  author={Falck, Fabian and Zhou, Yuyin and Rocheteau, Emma and Shen, Liyue and Oala, Luis and Abebe, Girmaw and Roy, Subhrajit and Pfohl, Stephen and Alsentzer, Emily and McDermott, Matthew},
  journal={arXiv e-prints},
  pages={arXiv--2112},
  year={2021}
}

@article{ramirez2022dataset,
  title={Dataset Similarity to Assess Semi-supervised Learning Under Distribution Mismatch Between the Labelled and Unlabelled Datasets},
  author={Ramirez, Saul Calderon and Oala, Luis and Torrentes-Barrena, Jordina and Yang, Shengxiang and Elizondo, David and Moemeni, Armaghan and Colreavy-Donnelly, Simon and Samek, Wojciech and Molina-Cabello, Miguel and Lopez-Rubio, Ezequiel},
  journal={IEEE Transactions on Artificial Intelligence},
  year={2022},
  publisher={IEEE}
}

@article{adler2022deutsche,
  title={Deutsche Normungsroadmap Künstliche Intelligenz},
  author={Adler, Rasmus and Bunte, Andreas and Burton, Simon and Gro{\ss}mann, J{\"u}rgen and Jaschke, Alexander and Kleen, Philip and Lorenz, Jeanette Miriam and Ma, Jackie and Markert, Karla and Mee{\ss}, Henri and others},
  year={2022},
  publisher={DIN}
}

@article{aversaphysical,
  title={Physical Data Models in Machine Learning Imaging Pipelines},
  author={Aversa, Marco and Oala, Luis and Clausen, Christoph and Dotphoton, AG and Murray-Smith, Roderick and Sanguinetti, Bruno}
}

@inproceedings{parziale2022machine,
  title={Machine Learning for Health (ML4H) 2022},
  author={Parziale, Antonio and Agrawal, Monica and Tang, Shengpu and Severson, Kristen and Oala, Luis and Subbaswamy, Adarsh and Kumar, Sayantan and Schoerverth, Elora and Hegselmann, Stefan and Zhou, Helen and others},
  booktitle={Machine Learning for Health},
  pages={1--11},
  year={2022},
  organization={PMLR}
}

@article{parziale2022machine,
  title={Machine Learning for Health symposium 2022--Extended Abstract track},
  author={Parziale, Antonio and Agrawal, Monica and Joshi, Shalmali and Chen, Irene Y and Tang, Shengpu and Oala, Luis and Subbaswamy, Adarsh},
  journal={arXiv preprint arXiv:2211.15564},
  year={2022}
}

@inproceedings{fehr2022piloting,
  title={Piloting A Survey-Based Assessment of Transparency and Trustworthiness with Three Medical AI Tools},
  author={Fehr, Jana and Jaramillo-Gutierrez, Giovanna and Oala, Luis and Gr{\"o}schel, Matthias I and Bierwirth, Manuel and Balachandran, Pradeep and Werneck-Leite, Alixandro and Lippert, Christoph},
  booktitle={Healthcare},
  volume={10},
  number={10},
  pages={1923},
  year={2022},
  organization={MDPI}
}

@article{oala2023data,
  title={Data Models for Dataset Drift Controls in Machine Learning With Optical Images},
  author={Oala, Luis and Aversa, Marco and Nobis, Gabriel and Willis, Kurt and Neuenschwander, Yoan and Buck, Mich{\`e}le and Matek, Christian and Extermann, Jerome and Pomarico, Enrico and Samek, Wojciech and others},
  journal={Transactions on Machine Learning Research (TMLR)},
  year={2023}
}

@article{aversa2023diffinfinite,
  title={DiffInfinite: Large Mask-Image Synthesis via Parallel Random Patch Diffusion in Histopathology},
  author={Aversa, Marco and Nobis, Gabriel and H{\"a}gele, Miriam and Standvoss, Kai and Chirica, Mihaela and Murray-Smith, Roderick and Alaa, Ahmed and Ruff, Lukas and Ivanova, Daniela and Samek, Wojciech and others},
  journal={arXiv preprint arXiv:2306.13384},
  year={2023}
}

@article{akogo2023localized,
  title={Localized Data Work as a Precondition for Data-Centric ML: A Case Study of Full Lifecycle Crop Disease Identification in Ghana},
  author={Akogo, Darlington and Samori, Issah and Akafia, Cyril and Fiagbor, Harriet and Kangah, Andrews and Asiedu, Donald Kwame and Fuachie, Kwabena and Oala, Luis},
  journal={arXiv preprint arXiv:2307.01767},
  year={2023}
}

@article{sectorfg,
  title={FG-AI4H DEL2. 2 Good practices for health applications of machine learning: Considerations for manufacturers and regulators},
  author={Sector, Standardization}
}

@article{parziale2022proceedings,
  title={Proceedings of the 2nd Machine Learning for Health symposium},
  author={Parziale, Antonio and Monica, Agrawal and Shalmali, Joshi and Chen, Irene Y and Shengpu, Tang and Luis, Oala and Adarsh, Subbaswamy and others},
  journal={PROCEEDINGS OF MACHINE LEARNING RESEARCH},
  volume={193},
  pages={1--577},
  year={2022},
  publisher={Cambridge MA: JMLR}
}

